#!/bin/sh
#
# Run freesurfer-recon-all Gear
# Built to flywheel-v0 spec.
#
# https://surfer.nmr.mgh.harvard.edu/fswiki/ReconAllOutputFiles

GEAR=anatrois
REPO=garikoitz
CONTAINER="[${REPO}/$GEAR]"

echo -e "$CONTAINER  Initiated"
set -e
set +o verbose   # Command echo off

# If run in debug mode, just exec bash:
if [ "$1" = "DEBUG" ]
    then exec /bin/bash
fi
if [ "$1" = "-h" ] || [ "$1" = "--help" ] || [ "$1" = "-help" ] || [ "$1" = "help" ]
    then cat /opt/help.txt
    exit 0
fi
# If it does not stop in the anteior part, then do this
source /opt/conda/etc/profile.d/conda.sh
conda activate scientific

###############################################################################
# Utilities

# Remove the spaces in directory and filenames recursively
despacer () {
  find "$1" -depth -name "* *" -execdir rename 's/ /_/g' "{}" \;
}

###############################################################################
# Configure Freesurfer and MCR ENV

export MCR_CACHE_FOLDER_NAME=.mcrCache8.4

export OS=Linux
export FS_OVERRIDE=0
export FIX_VERTEX_AREA=
export FSF_OUTPUT_FORMAT=nii.gz
export MNI_DIR=/opt/freesurfer/mni
export LOCAL_DIR=/opt/freesurfer/local
export FREESURFER_HOME=/opt/freesurfer
export FREESURFER=/opt/freesurfer
export FSFAST_HOME=/opt/freesurfer/fsfast
export MINC_BIN_DIR=/opt/freesurfer/mni/bin
export MINC_LIB_DIR=/opt/freesurfer/mni/lib
export MNI_DATAPATH=/opt/freesurfer/mni/data
export FMRI_ANALYSIS_DIR=/opt/freesurfer/fsfast
export PERL5LIB=/opt/freesurfer/mni/lib/perl5/5.8.5
export MNI_PERL5LIB=/opt/freesurfer/mni/lib/perl5/5.8.5
export XAPPLRESDIR=/opt/freesurfer/MCRv84/X11/app-defaults
export PATH=/opt/freesurfer/bin:/opt/freesurfer/fsfast/bin
export PATH=$PATH:/opt/freesurfer/tktools:/opt/freesurfer/mni/bin
export PATH=$PATH:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin
export PATH=$PATH:/sbin:/bin
###############################################################################
# Configure paths

FLYWHEEL_BASE=/flywheel/v0
OUTPUT_DIR=${FLYWHEEL_BASE}/output
INPUT_DIR=${FLYWHEEL_BASE}/input
ANAT_DIR=${INPUT_DIR}/anat
PRE_FS_DIR=${INPUT_DIR}/pre_fs
MNIROIZIP_DIR=${INPUT_DIR}/mniroizip
ANNOTFILE_DIR=${INPUT_DIR}/annotfile
ANAT_DIR_2=${INPUT_DIR}/t1w_anatomical_2
ANAT_DIR_3=${INPUT_DIR}/t1w_anatomical_3
ANAT_DIR_4=${INPUT_DIR}/t1w_anatomical_4
ANAT_DIR_5=${INPUT_DIR}/t1w_anatomical_5
T2_DIR=${INPUT_DIR}/t2w_anatomical
LICENSE_FILE=${OUTPUT_DIR}/.license
TEMPLATES=${OUTPUT_DIR}/templates
MORI_DIR=${TEMPLATES}/MNI_JHU_tracts_ROIs
FS_DIR=${OUTPUT_DIR}/fs
ROIs_DIR=${OUTPUT_DIR}/fs/ROIs
export MCR_CACHE_ROOT=${OUTPUT_DIR}
# Source FreeSurferEnv.sh then set subjects_dir
/bin/bash -c 'source $FREESURFER_HOME/FreeSurferEnv.sh &>/dev/null'

export SUBJECTS_DIR=${OUTPUT_DIR}

###############################################################################
# Parse Configuration and Set Options

CONFIG_FILE=${FLYWHEEL_BASE}/config.json
MANIFEST_FILE=${FLYWHEEL_BASE}/manifest.json

if [[ ! -f ${CONFIG_FILE} ]]; then
  CONFIG_FILE=${MANIFEST_FILE}
fi

# If the license file is empty then create from config inputs
if [[ ! -f ${LICENSE_FILE} ]]; then
  LICENSE=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -l)
  if [[ -z $LICENSE ]]; then
    echo "NO LICENSE INFORMATION FOUND! Exiting(1)"
    exit 1
  fi
  echo -e ${LICENSE} > ${LICENSE_FILE}
fi

SUBJECT_ID=$(echo $(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -i) | sed 's/ /_/g')
RECON_ALL_OPTS=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -o)
CONVERT_SURFACES=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -s)
CONVERT_VOLUMES=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -n)
ASEG_CSV=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -a)
HIPPOCAMPUS=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -c)
BRAINSTEM=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -b)
THALAMUS=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -t)
HCP=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -g)
NEUROPYTHY=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -p)
REGISTER_SURFACES=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -r)
CEREBELLUM=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -e)
MORI=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -m)
APARC2009=$(${FLYWHEEL_BASE}/parse_config.py --json_file=${CONFIG_FILE} -aparc2009)
# Make and link the subject's directory
WORK_DIR=${OUTPUT_DIR}/"${SUBJECT_ID}"
#ln -sfn ${SUBJECTS_DIR}/"${SUBJECT_ID}" ${WORK_DIR}
export FS_LICENSE=${LICENSE_FILE}

MRI_DIR=${SUBJECTS_DIR}/"${SUBJECT_ID}"/mri
if [[ ! -d $FS_DIR ]]; then
  mkdir ${FS_DIR}
fi

if [[ ! -d $ROIs_DIR ]]; then
  mkdir ${ROIs_DIR}
fi

###############################################################################
# This is new in version 4.0.0
# Now the container will have the option to include a folder or a zip file with FS run already
# This zip file or folder is going to be optional. Therefore, if there is no zip, there should be the anatomical file
# and it will run the whole FS. 

# Additionnally, now we have a new mandatory file, and it is going to be a zip file with the MNI atlas file and the ROIs in 
# MNI space. Now we will read and unzip those files. 

# Despace filenames
# despacer "${ANAT_DIR}"
# despacer "${PRE_FS_DIR}"
# despacer "${MNIROIZIP_DIR}"

# Check wich one of the two have been provided. If both, use the existing one. If none, error. 
if [[ -d ${ANAT_DIR}  &&  -d ${PRE_FS_DIR} ]]; then
    DO_FS="False"
    echo "$CONTAINER Both folders ${ANAT_DIR} and ${PRE_FS_DIR} exist, we will use the pre-run FS by default. "
fi
if [[ ! -d "${ANAT_DIR}"  &&  !  -d "${PRE_FS_DIR}" ]]; then
    echo "$CONTAINER No input folders ${ANAT_DIR} or ${PRE_FS_DIR} exist, add at least one for the container to run. "
    exit 1
fi
if [[ -d "${ANAT_DIR}"  &&  ! -d "${PRE_FS_DIR}" ]]; then
    echo "$CONTAINER  ${ANAT_DIR} exist but ${PRE_FS_DIR} not, We will run FS with the options ${RECON_ALL_OPTS}"
    DO_FS="True"
fi
if [[ ! -d "${ANAT_DIR}" && -d "${PRE_FS_DIR}" ]]; then
    echo "$CONTAINER  ${ANAT_DIR} does not exist but ${PRE_FS_DIR} exists, we will use the existing FS run"
    DO_FS="False"
fi

# Check if the annotation have been provided, if yes, we will convert to individual space annot and volume labels
DO_ANNOT="False"
if [[ -d "${ANNOTFILE_DIR}" ]]; then
    echo "$CONTAINER ${ANNOTFILE_DIR} exists, checking if the file exists now"

    # Get the zip filename
    ANNOTFILE=$(find ${ANNOTFILE_DIR}/* -name "*.zip")
    
    if [[ -f "${ANNOTFILE}" ]]; then
        echo "$CONTAINER ${ANNOTFILE} exists, it will create individual ROIs out of it"
        DO_ANNOT="True"
    fi
fi





# IF MNIROIZIP is provided, then delete the previous folder and substitute with this one
# Do it right here, do not use variables, it should be transpartent to the run file because the other roi-s come from Dockerfile
if [[ -d ${TEMPLATES} ]]; then
    rm -rf ${TEMPLATES}
fi

mkdir ${TEMPLATES}
if [[ -d "${MNIROIZIP_DIR}" ]]; then
    echo "$CONTAINER  ${MNIROIZIP_DIR} have been provided and it will substitute the default one"
    # Get the zip filename
    MNIROIZIP=$(find ${MNIROIZIP_DIR}/* -name "*.zip")
    # Unzip the new
    unzip ${MNIROIZIP} -d ${MORI_DIR}
    # Copy the files, not the folder
    cp /flywheel/v0/templates/*.* ${TEMPLATES} 
else
    cp -r /flywheel/v0/templates/* ${TEMPLATES} 
fi





















##############################################################################
if [[ ${DO_FS} == "True" ]]; then
    # Check for anatomical NIfTI or DICOM archive
    
    # NIfTI input file
    ANATOMICAL=$(find ${ANAT_DIR}/* -name "*.nii*")
    
    # DICOM archive
    if [[ -z "${ANATOMICAL}" ]]; then
      ANATOMICAL=$(find $INPUT_DIR/* -not -path '*/\.*' -type f | head -1)
    
      # Handle Zip archive or uncompressed volume
      if [[ "${ANATOMICAL}" == *.zip ]]; then
        echo "$CONTAINER  Unzipping $ANATOMICAL"
        DICOM_DIR="${ANAT_DIR}"/dicoms
        mkdir ${DICOM_DIR}
        unzip -q "${ANATOMICAL}" -d ${DICOM_DIR}
    
        # Get the 'despaced' path to the first dicom file for input to recon-all
        despacer "${DICOM_DIR}"
        ANATOMICAL=$(find ${DICOM_DIR}/* -not -path '*/\.*' -type f | head -1)
      fi
    
      # Final check for anatomical file
      if [[ -z "${ANATOMICAL}" ]]; then
        echo "$CONTAINER  Anatomical input could not be found in $ANAT_DIR! Exiting (1)"
        ls -lRa ${ANAT_DIR}
        exit 1
      fi
    fi
    
    # Proccess additional anatomical inputs
    ADD_INPUTS=''
    ANAT_DIRS=$(echo -e $ANAT_DIR_2 $ANAT_DIR_3 $ANAT_DIR_4 $ANAT_DIR_5)
    for ad in $ANAT_DIRS; do
      if [[ -d ${ad} ]]; then
        despacer ${ad}
        ANATOMICAL2=$(find ${ad}/* -name "*.nii*")
        if [[ -f "$ANATOMICAL2" ]]; then
          echo "Adding $ANATOMICAL2 to the processing stream..."
          ADD_INPUTS=$ADD_INPUTS' -i '"$ANATOMICAL2"
        fi
      fi
    done
    
    # T2 input file
    if [[ -d ${T2_DIR} ]]; then
      despacer ${T2_DIR}
      T2_ANAT=$(find ${T2_DIR}/* -name "*.nii*")
      if [[ -f "$T2_ANAT" ]]; then
        ADD_INPUTS=$ADD_INPUTS' -T2 '"$T2_ANAT"' -T2pial '
      fi
    fi
    
    ###############################################################################
    # Run Freesurfer-Recon-all
    if [[  ${RECON_ALL_OPTS} == "False" ]];then
      echo -e "recon all is false, skipping it"
      echo -e "checking if the old freesurfer-recon-all*.zip is there"
      FS_ARCHIVE=$(find ${OUTPUT_DIR}/* -name "freesurfer-recon-all*.zip")
      if [[ -f "$FS_ARCHIVE" ]]; then
          echo -e "unzipping existing ${FS_ARCHIVE}"
          unzip -oq "${FS_ARCHIVE}" -d "${OUTPUT_DIR}"
      else
          echo -e "$CONTAINER We cannot find existing .zip file"
          echo "$CONTAINER  GEAR FAILED... Exiting(1)"
          exit 1
      fi
      # echo -e "linking SUBJECTS_DIR directory to freesurfer"
      # ln -sfn ${OUTPUT_DIR}/${SUBJECT_ID} ${SUBJECTS_DIR}/"${SUBJECT_ID}"
    else 
        # Run recon-all
        echo -e "Running recon all..."
        command=$(echo -e "time recon-all -i "${ANATOMICAL}" "${ADD_INPUTS}" -subjid "${SUBJECT_ID}" ${RECON_ALL_OPTS}")
        echo -e "${command}"
        eval $command
        
        # Remove the symbolic link
        unlink ${OUTPUT_DIR}/fsaverage

    fi
    if [[ $? != 0 ]]; then
      echo "$CONTAINER  recon-all failure! Exiting (1)"
      exit 1
    fi
else
    # We are not running FS, we need to find a zip file or a folder with a previous run
    # If it is a zip file just search any zip file in the folder and unzip it. 
    # If it is a folder, it will be a symbolic link to a FS folder, we are not going to copy anything. 
    # Be careful with the file writing, as it will write in the FS folders. Then we copy to the output 
    #   the files we are interested to the output and the rest will be zipped. 
     
    # NIfTI input file
    PRE_FS_ZIP=$(find ${PRE_FS_DIR}/* -name "*.zip")
    PRE_FS_LNK=$(find ${PRE_FS_DIR}/* -name ${SUBJECT_ID})
    echo "$CONTAINER PRE_FS_ZIP is $PRE_FS_ZIP"
    echo "$CONTAINER PRE_FS_LNK is $PRE_FS_LNK"
    
    if [[ "${PRE_FS_ZIP}"  &&  "${PRE_FS_LNK}" ]]; then
        USE_ZIP="False"
        echo "$CONTAINER Both folders ZIP and LINK found, we will use the LINK. "
    fi
    if [[ ! "${PRE_FS_ZIP}"  &&   "${PRE_FS_LNK}" ]]; then
        echo "$CONTAINER Link to existing FS run found, it will be used. "
        USE_ZIP="False"
    fi
    if [[ "${PRE_FS_ZIP}"  &&  ! "${PRE_FS_LNK}" ]]; then
        echo "$CONTAINER   Zip with existing FS run found, We will run FS with the options ${RECON_ALL_OPTS}"
        USE_ZIP="True"
    fi
    if [[ ! "${PRE_FS_ZIP}"  &&  ! "${PRE_FS_LNK}" ]]; then
        echo "$CONTAINER  No link or zip found in ${PRE_FS_DIR}, exiting"
        exit 1
    fi
    # If use zip, unzip it, else check the link it is working well
    if [[ ${USE_ZIP} == "True" ]]; then
        echo "$CONTAINER Unzipping existing FS ZIP"
        unzip ${PRE_FS_ZIP} -d ${OUTPUT_DIR}
        # Check that the subject name in the zip is the same one as in the config file
        if [[ ! -d $OUTPUT_DIR/${SUBJECT_ID} ]]; then
            echo "$CONTAINER The subject_id in config file ${SUBJECT_ID} is not the same as the folder name in the zip file"
            exit 1
        fi
    else
        echo "$CONTAINER Checking that the link to the FS has the same name as in the config file..."
        ln -s $PRE_FS_LNK $OUTPUT_DIR/${SUBJECT_ID}
        if [[ -d $OUTPUT_DIR/${SUBJECT_ID} ]]; then
            echo "$CONTAINER  ... done. "
        else
            echo "$CONTAINER ... failed, exiting"
            exit 1
        fi
    fi
fi 
# FREESURFER ENDS HERE



















###############################################################################
# Optional Segmentations

# This will be a considerable time saver. 
# When ANTs has been run, it saves info in the FS folder. 
# Before running any of the below transformations, check that the required files are not already there. 



# Segmentation of Cerebellum 
if [[ ${CEREBELLUM} == "True" ]]; then
  echo -e "$CONTAINER starting segmentation of cerebellum"
  if [[ ! -f  ${MRI_DIR}/ants1Warp.nii.gz ]]; then 
    # Create binary mask of brainmask.mgz and MNI_152
    mri_convert  ${MRI_DIR}/brainmask.mgz ${MRI_DIR}/brainmask.nii.gz
    # calculate the transformation
    antsRegistrationSyN.sh -d 3 -o ${MRI_DIR}/ants                          \
        -f ${MRI_DIR}/brainmask.nii.gz -m ${MORI_DIR}/FSL_MNI152_FreeSurferConformed_1mm.nii.gz
  fi
  # apply both affine and nonlinear transofrmation
  antsApplyTransforms -d 3                                                      \
        -i ${TEMPLATES}/Cerebellum-MNIsegment.nii.gz                            \
        -r ${MRI_DIR}/brainmask.nii.gz                                          \
        -n GenericLabel[Linear]                                                 \
        -t ${MRI_DIR}/ants1Warp.nii.gz                                          \
        -t ${MRI_DIR}/ants0GenericAffine.mat                                    \
        -o ${MRI_DIR}/Cerebellum-MNIsegment_ind.nii.gz
  # copy it to output dir
  mv ${MRI_DIR}/Cerebellum-MNIsegment_ind.nii.gz \
            ${OUTPUT_DIR}/Cerebellum-MNIsegment_ind.nii.gz
fi
# transform MORI to native spac
# TODO: add e
if [[ ${MORI} == "True" ]]; then
  echo -e "$CONTAINER starting transform MORI"
  # if [[ ${CEREBELLUM} != "True" ]]; then  # This was a bad check, check if the transform file is there
  if [[ ! -f  ${MRI_DIR}/ants1Warp.nii.gz ]]; then 
    # Create binary mask of brainmask.mgz and MNI_152
    mri_convert  ${MRI_DIR}/brainmask.mgz ${MRI_DIR}/brainmask.nii.gz
    # calculate the transformation
    antsRegistrationSyN.sh -d 3 -o ${MRI_DIR}/ants                          \
        -f ${MRI_DIR}/brainmask.nii.gz -m ${MORI_DIR}/FSL_MNI152_FreeSurferConformed_1mm.nii.gz
  fi
  for ROI in `ls ${MORI_DIR}/*`; do
  	if [[ $ROI == ${MORI_DIR}/FSL_MNI152_FreeSurferConformed_1mm.nii.gz ]];then
        continue
    fi
    
    ROIname=$(basename -- "$ROI"); ROIname="${ROIname%.nii.gz}"  
    antsApplyTransforms -d 3                                                \
        -i ${MORI_DIR}/${ROIname}.nii.gz                                    \
        -r ${MRI_DIR}/brainmask.nii.gz                                      \
        -n GenericLabel[Linear]                                             \
        -t ${MRI_DIR}/ants1Warp.nii.gz                                      \
        -t ${MRI_DIR}/ants0GenericAffine.mat                                \
        -o ${MRI_DIR}/MORI_${ROIname}.nii.gz
    
    mri_binarize --min 0.1 --i ${MRI_DIR}/MORI_${ROIname}.nii.gz \
                        --o ${ROIs_DIR}/${ROIname}.nii.gz
    rm ${MRI_DIR}/MORI_${ROIname}.nii.gz 
  done
fi

# transform HCP atlas to native space
if [[ ${HCP} == "True" ]]; then
  echo -e "$CONTRAINER starting transform HCP atlas to native space"
  if [[ ! -f  ${MRI_DIR}/ants1Warp.nii.gz ]]; then 
    # Create binary mask of brainmask.mgz and MNI_152
    mri_convert  ${MRI_DIR}/brainmask.mgz ${MRI_DIR}/brainmask.nii.gz
    # calculate the transformation
    antsRegistrationSyN.sh -d 3 -o ${MRI_DIR}/ants                              \
        -f ${MRI_DIR}/brainmask.nii.gz -m ${MORI_DIR}/FSL_MNI152_FreeSurferConformed_1mm.nii.gz
  fi
  # apply both affine and nonlinear transofrmation
  antsApplyTransforms -d 3                                                      \
        -i ${TEMPLATES}/MNI_Glasser_HCP_v1.0.nii.gz                             \
        -r ${MRI_DIR}/brainmask.nii.gz                                          \
        -n GenericLabel[Linear]                                                 \
        -t ${MRI_DIR}/ants1Warp.nii.gz                                          \
        -t ${MRI_DIR}/ants0GenericAffine.mat                                    \
        -o ${MRI_DIR}/Glasser_HCP_v1.0.nii.gz
  # copy it to output dir
  mv ${MRI_DIR}/Glasser_HCP_v1.0.nii.gz          \
            ${OUTPUT_DIR}/Glasser_HCP_v1.0.nii.gz
fi

    
export LD_LIBRARY_PATH=/opt/freesurfer/MCRv84/runtime/glnxa64:/opt/freesurfer/MCRv84/bin/glnxa64:/opt/freesurfer/MCRv84/sys/os/glnxa64:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64/native_threads:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64/server:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64


# Segmentation of hippocampal subfields
if [[ ${HIPPOCAMPUS} == "True" ]]; then
  echo -e "$CONTAINER  Starting segmentation of hippocampal subfields..."
  # OLD: recon-all -subjid "${SUBJECT_ID}" -hippocampal-subfields-T1
  # DEV:
  segmentHA_T1.sh "${SUBJECT_ID}"

  # if T2 input file
  if [[ -f "$T2_ANAT" ]]; then
    segmentHA_T2.sh "${SUBJECT_ID}" ${MRI_DIR}/T2.mgz 0 1
  fi

  # Longitudinal Processing of Hippocampus: NOT PERFORMING
  # segmentHA_T1_long.sh "${SUBJECT_ID}"
  # OLD: 
  # quantifyHippocampalSubfields.sh T1 "${MRI_DIR}"/HippocampalSubfields.txt
  # DEV:
  quantifyHAsubregions.sh hippoSf T1 "${MRI_DIR}"/HippocampalSubfields.txt ${SUBJECTS_DIR}
  quantifyHAsubregions.sh amygNuc T1 "${MRI_DIR}"/AmygdalaNuclei.txt ${SUBJECTS_DIR}
  # TODO: This is going to have to be parsed out.
  tr ' ' ',' <"${MRI_DIR}"/HippocampalSubfields.txt >${OUTPUT_DIR}/"${SUBJECT_ID}"_HippocampalSubfields.csv
  tr ' ' ',' <"${MRI_DIR}"/AmygdalaNuclei.txt >${OUTPUT_DIR}/"${SUBJECT_ID}"_AmygdalaNuclei.csv
fi

# Brainstem Substructures
if [[ ${BRAINSTEM} == "True" ]]; then
  echo -e "$CONTAINER  Starting segmentation of brainstem structures..."
  # OLD: recon-all -subjid "${SUBJECT_ID}" -brainstem-structures
  # DEV: 
  segmentBS.sh "${SUBJECT_ID}"
  quantifyBrainstemStructures.sh "${MRI_DIR}"/BrainstemStructures.txt
  tr ' ' ',' <"${MRI_DIR}"/BrainstemStructures.txt >${OUTPUT_DIR}/"${SUBJECT_ID}"_BrainstemStructures.csv
fi

# Thalamic Nuclei

# For testing
# mv ${MRI_DIR}/aparc.a2009s+aseg.mgz ${MRI_DIR}/aparc.a2009s+aseg_TEST.mgz
# rm -rf ${OUTPUT_DIR}/${SUBJECT_ID}/scripts
# rm -rf ${OUTPUT_DIR}/${SUBJECT_ID}/tmp

if [[ ${THALAMUS} == "True" ]]; then
    # Check if this is infant, if so, modify aseg.mgz
    if [[ ! -f ${MRI_DIR}/aparc.a2009s+aseg.mgz  ]]; then
        echo "$CONTAINER InfantFS detected, removing LD_LIBRARY_PATH and running fix_aseg_if_infant.py"
        export LD_LIBRARY_PATH=""
        echo "$CONTAINER This is LD_LIBRARY_PATH: $LD_LIBRARY_PATH "
        # aseg is different, change it, required for Thalamic Segmentation
        ${FLYWHEEL_BASE}/fix_aseg_if_infant.py -mriDir ${MRI_DIR}


        export LD_LIBRARY_PATH=/opt/freesurfer/MCRv84/runtime/glnxa64:/opt/freesurfer/MCRv84/bin/glnxa64:/opt/freesurfer/MCRv84/sys/os/glnxa64:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64/native_threads:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64/server:/opt/freesurfer/MCRv84/sys/java/jre/glnxa64/jre/lib/amd64
    
        echo "$CONTAINER This is LD_LIBRARY_PATH: $LD_LIBRARY_PATH "

        echo "$CONTAONER Check if scripts and tmp directories exist in InfantFS"
        if [[ ! -d ${OUTPUT_DIR}/${SUBJECT_ID}/scripts  ]]; then
            mkdir ${OUTPUT_DIR}/${SUBJECT_ID}/scripts
        fi
        if [[ ! -d ${OUTPUT_DIR}/${SUBJECT_ID}/tmp  ]]; then
            mkdir ${OUTPUT_DIR}/${SUBJECT_ID}/tmp
        fi
    fi


    echo -e "$CONTAINER  Starting segmentation of thalamic nuclei..."
    segmentThalamicNuclei.sh "${SUBJECT_ID}"
    fixAllSegmentations  ${SUBJECTS_DIR}/"${SUBJECT_ID}"
    # With nightly builds, "${MRI_DIR}"/ThalamicNuclei.${SUFFIX}.T1.volumes.txt
    # ${SUFFIX} is unstable
    ln -sfn "${MRI_DIR}"/ThalamicNuclei.*.T1.fixed_FRAC_0.6.volumes.txt "${MRI_DIR}"/ThalamicNuclei.T1.volumes.txt
    tr ' ' ',' <"${MRI_DIR}"/ThalamicNuclei.T1.volumes.txt >${OUTPUT_DIR}/"${SUBJECT_ID}"_ThalamicNuclei.T1.volumes.csv

fi

# export LD_LIBRARY_PATH=""


# Run the conda config again, to be sure we are using the right python
conda deactivate
source /opt/conda/etc/profile.d/conda.sh
conda activate scientific
python --version


# Neuropythy retino-template algorithm
if [[ ${NEUROPYTHY} == "True" ]]; then
    echo -e "$CONTAINER  Starting Neuropythy retino-template ..."
    # Matlab installation interfers with neuropythy execution.
    SAVE_LD_LIBRARY_PATH=$LD_LIBRARY_PATH
    export LD_LIBRARY_PATH=
    # With new version sometimes does not found the atlas, weird...
    # Do it in python as regardless we are going to move all to python functions
    # python -m neuropythy atlas --verbose --volume-export "${SUBJECT_ID}"
    # I will call the whole function run.py as little by little it will be incorporating all the bash functions
    python ${FLYWHEEL_BASE}/run.py "$CONFIG_FILE" || die "Python startup script failed!" 
    export LD_LIBRARY_PATH=$SAVE_LD_LIBRARY_PATH
fi
###############################################################################
# Optional registrations

if [[ $REGISTER_SURFACES == "True" ]]; then
  echo -e "$CONTAINER  Running surface registrations..."
  # Register hemispheres
  xhemireg --s "${SUBJECT_ID}"

  # Register the left hemisphere to fsaverage_sym
  # surfreg --s "${SUBJECT_ID}" --t fsaverage_sym --lh

  # Register the inverted right hemisphere to fsaverage_sym
  # surfreg --s "${SUBJECT_ID}" --t fsaverage_sym --lh --xhemi
fi


###############################################################################
# Convert the output surface and volume files
if [[ $CONVERT_SURFACES == "True" ]]; then

  # Convert selected surfaces in subject/surf to obj in output
  SURF_DIR=${SUBJECTS_DIR}/"${SUBJECT_ID}"/surf

  surfaces='lh.pial
            rh.pial
            lh.white
            rh.white
            rh.inflated
            lh.inflated'

  echo -e "$CONTAINER  Converting surfaces to object (.obj) files..."
  for i in $surfaces; do
      mris_convert "${SURF_DIR}"/$i "${SURF_DIR}"/$i.asc
      ${FLYWHEEL_BASE}/srf2obj "${SURF_DIR}"/$i.asc > ${OUTPUT_DIR}/$i.obj
  done

fi




# Just in case, convert always volumes, we need some later
CONVERT_VOLUMES="True"

# Convert select volumes in subject/mri to nifti:
if [[ $CONVERT_VOLUMES == "True" ]]; then

  MRI_DIR=${SUBJECTS_DIR}/"${SUBJECT_ID}"/mri
  if [[ -f ${MRI_DIR}/aparc.a2009s+aseg.mgz  ]]; then
      mri_mgz_files='aparc+aseg.mgz
                     aparc.a2009s+aseg.mgz
                     brainmask.mgz
                     lh.ribbon.mgz
                     rh.ribbon.mgz
                     ribbon.mgz
                     aseg.mgz
                     orig.mgz
                     T1.mgz'
  else
      # It must be infant, not all files are there:
      mri_mgz_files='aparc+aseg.mgz
                     brainmask.mgz
                     lh.ribbon.mgz
                     rh.ribbon.mgz
                     ribbon.mgz
                     aseg.mgz'
                     

  fi
  if [[ ${HIPPOCAMPUS} == "True" ]]; then
    # Create a symbolic link to the development version of this output specified
    # by ${SUFFIX} in 
    # rh.hippoSfLabels-T1.${SUFFIX}.FSvoxelSpace.mgz"

    ln -sfn `ls "${MRI_DIR}"/lh.hippoAmygLabels-T1.*.FSvoxelSpace.mgz | egrep 'T1.v[0-9]+.FSvox'` "${MRI_DIR}"/lh.hippoAmygLabels-T1.FSvoxelSpace.mgz
    ln -sfn `ls "${MRI_DIR}"/rh.hippoAmygLabels-T1.*.FSvoxelSpace.mgz | egrep 'T1.v[0-9]+.FSvox'` "${MRI_DIR}"/rh.hippoAmygLabels-T1.FSvoxelSpace.mgz
    mri_mgz_files="$mri_mgz_files 
                   lh.hippoAmygLabels-T1.FSvoxelSpace.mgz
                   rh.hippoAmygLabels-T1.FSvoxelSpace.mgz"
  fi

  if [[ ${BRAINSTEM} == "True" ]]; then
    # Create a symbolic link to the development version of this output specified
    # by ${SUFFIX} in 
    # brainstemSsLabels.${SUFFIX}.FSvoxelSpace.mgz
    ln -sfn "${MRI_DIR}"/brainstemSsLabels.*.FSvoxelSpace.mgz "${MRI_DIR}"/brainstemSsLabels.FSvoxelSpace.mgz
    mri_mgz_files="$mri_mgz_files brainstemSsLabels.FSvoxelSpace.mgz"
  fi

  if [[ ${THALAMUS} == "True" ]]; then
    # Create a symbolic link to the development version of this output specified
    # by ${SUFFIX} in 
    # ThalamicNuclei.${SUFFIX}.T1.FSvoxelSpace.mgz
    ln -sfn "${MRI_DIR}"/ThalamicNuclei.*.T1.FSvoxelSpace.mgz "${MRI_DIR}"/ThalamicNuclei.T1.FSvoxelSpace.mgz
    mri_mgz_files="$mri_mgz_files ThalamicNuclei.T1.FSvoxelSpace.mgz"
  fi

  if [[ ${NEUROPYTHY} == "True" ]]; then
    mri_mgz_files="$mri_mgz_files 
                   wang15_mplbl.mgz
                   benson14_varea.mgz
                   benson14_eccen.mgz
                   benson14_sigma.mgz
                   benson14_angle.mgz"
  fi

  echo -e "$CONTAINER  Converting volumes to NIfTI files..."
  for i in $mri_mgz_files; do
    mri_convert -i "${MRI_DIR}"/$i -o ${OUTPUT_DIR}/`basename $i .mgz`.nii.gz
    mri_convert -i "${MRI_DIR}"/$i -o ${FS_DIR}/`basename $i .mgz`.nii.gz
  done
fi

# Do the annotation conversion now
if [[ ${DO_ANNOT} == "True" ]]; then
    # Unzip the annot file first
    ANNOTDIRS=${OUTPUT_DIR}/annotations
    # Create the folder and unzip 
    mkdir ${ANNOTDIRS}
    unzip $ANNOTFILE -d ${ANNOTDIRS}

    # Labeldir in the subject
    labeldir=${OUTPUT_DIR}/${SUBJECT_ID}/label/
    labeldirtmp=${OUTPUT_DIR}/${SUBJECT_ID}/label/tmp
    if [[ ! -d ${labeldirtmp} ]]; then
        mkdir ${labeldirtmp}
    fi

    # Create symbolink link to fsaverage to the output folder
    fsaveragelink=${OUTPUT_DIR}/fsaverage
    # ln -s $FREESURFER_HOME/subjects/fsaverage $fsaveragelink
    # Error thrown with ln, try copying, singularity problem, not docker
    # Check if the symbolic link exists, if so, unlink it
    if [[ -L ${fsaveragelink} && -d ${fsaveragelink} ]]; then
        echo "Unlinking existing link to fsaverage"
        unlink ${fsaveragelink}
    fi
    if [[ ! -d ${fsaveragelink}  ]]; then
        echo "Copying fsaverage"
        cp -r $FREESURFER_HOME/subjects/fsaverage ${OUTPUT_DIR}
    fi
    
    # Convert the annot from fsaverage to the individual subject space
    for annot in `ls ${ANNOTDIRS}/*`; do
        ANNOTname=$(basename -- "$annot"); ANNOTname="${ANNOTname%.annot}"
        
        # Obtain hemi
        hemi=${ANNOTname:0:2}

        
        # Launch the first command to convert to individual subject space  
        mri_surf2surf --srcsubject fsaverage --trgsubject ${SUBJECT_ID} --hemi ${hemi} \
                      --sval-annot ${ANNOTDIRS}/${ANNOTname}.annot --tval ${labeldir}/${ANNOTname}.annot
        
        # # Extract the individual labels
        # # --labelbase ${ANNOTname}
        mri_annotation2label --subject ${SUBJECT_ID} --hemi ${hemi}  \
                             --annotation ${labeldir}/${ANNOTname}.annot --outdir $labeldirtmp
        
        # Convert from label to volumetric label (add this to fill GM, otherwise just pial voxels -proj frac 0 1 0.01)
        for label in `ls ${labeldirtmp}/*`; do
            LABELname=$(basename -- "$label"); LABELname="${LABELname%.label}"
            mri_label2vol --label ${labeldirtmp}/${LABELname}.label --subject ${SUBJECT_ID} \
                                --hemi  ${hemi} --identity \
                                --temp ${OUTPUT_DIR}/${SUBJECT_ID}/mri/T1.mgz \
                                --o ${ROIs_DIR}/${LABELname}.nii.gz
            # Move the label file to the label dir to store
            mv ${labeldirtmp}/${LABELname}.label ${labeldir}/${LABELname}.label
            # Do this to fill the holes and make it fit exactly inside the boundaries of GM (we control dilation later to be dMRI WM ROIs)
            mri_binarize --dilate 1 --erode 1 --i ${ROIs_DIR}/${LABELname}.nii.gz \
                         --o ${ROIs_DIR}/${LABELname}.nii.gz --min 1
            mris_calc -o ${ROIs_DIR}/${LABELname}.nii.gz ${ROIs_DIR}/${LABELname}.nii.gz \
                          mul ${OUTPUT_DIR}/${SUBJECT_ID}/mri/${hemi}.ribbon.mgz    
        done
    done
    # Remove the symbolic link 
    # unlink $fsaveragelink
    # Delete fsaverage folder copy
    rm -rf ${fsaveragelink}
fi




























##############################################################################
# Run the conda config again, to be sure we are using the right python
conda deactivate
source /opt/conda/etc/profile.d/conda.sh
conda activate scientific
python --version


# Write ROIs separately into individual files
if [[ -f  ${OUTPUT_DIR}/aparc+aseg.nii.gz ]]; then
    cp ${OUTPUT_DIR}/aparc+aseg.nii.gz   ${FS_DIR}/aparc+aseg.nii.gz
fi

# Cerebellum
if [[ ${CEREBELLUM} == "True" ]]; then
    cp ${OUTPUT_DIR}/Cerebellum-MNIsegment_ind.nii.gz  ${FS_DIR}/Cerebellum-MNIsegment_ind.nii.gz
    # ${FLYWHEEL_BASE}/separateROIs.py -cb ${FS_DIR}/buckner2011_cerebellum.nii.gz
    mri_extract_label ${FS_DIR}/Cerebellum-MNIsegment_ind.nii.gz 29 ${FS_DIR}/ROIs/Left-Dentate.nii.gz
    mri_extract_label ${FS_DIR}/Cerebellum-MNIsegment_ind.nii.gz 30 ${FS_DIR}/ROIs/Right-Dentate.nii.gz
fi

# Thalamic Nuclei
if [[ ${THALAMUS} == "True" ]]; then
    # separate nuclei from the ThalamicNuclei.T1.FSvoxelSpace.nii.gz
    # separate ROIs
    cp "${MRI_DIR}"/ThalamicNuclei.v12.T1.FSvoxelSpace.fixed_FRAC_0.6.nii.gz "${OUTPUT_DIR}"/ThalamicNuclei.v12.T1.FSvoxelSpace.fixed_FRAC_0.6.nii.gz
    cp ${OUTPUT_DIR}/ThalamicNuclei.v12.T1.FSvoxelSpace.fixed_FRAC_0.6.nii.gz ${FS_DIR}/ThalamicNuclei.v12.T1.FSvoxelSpace.fixed_FRAC_0.6.nii.gz
    ${FLYWHEEL_BASE}/separateROIs.py -ThN ${FS_DIR}/ThalamicNuclei.v12.T1.FSvoxelSpace.fixed_FRAC_0.6.nii.gz \
                                     -ThLUT ${TEMPLATES}/FreesurferColorLUT_THALAMUS.txt 
    
fi

# HCP Atlas
if [[ ${HCP} == "True" ]]; then
    # separate ROIs
    cp ${OUTPUT_DIR}/Glasser_HCP_v1.0.nii.gz ${FS_DIR}/Glasser_HCP_v1.0.nii.gz

    ${FLYWHEEL_BASE}/separateROIs.py -hcp ${FS_DIR}/Glasser_HCP_v1.0.nii.gz \
                                     -hcpLUT ${TEMPLATES}/LUT_HCP.txt
    # create motor and auditory cortex ROIs
    for hemi in L R
    do
        3dcalc -a ${ROIs_DIR}/${hemi}_Primary_Auditory_Cortex.nii.gz \
               -b ${ROIs_DIR}/${hemi}_Lateral_Belt_Complex.nii.gz \
               -c ${ROIs_DIR}/${hemi}_Medial_Belt_Complex.nii.gz \
               -d ${ROIs_DIR}/${hemi}_ParaBelt_Complex.nii.gz \
               -expr 'step(a+b+c+d)' \
               -prefix ${ROIs_DIR}/${hemi}_A1_Belt.nii.gz -overwrite
        3dcalc -a ${ROIs_DIR}/${hemi}_Area_6_anterior.nii.gz \
               -b ${ROIs_DIR}/${hemi}_Dorsal_area_6.nii.gz \
               -expr 'step(a+b)' \
               -prefix ${ROIs_DIR}/${hemi}_dlPremotor.nii.gz -overwrite
        3dcalc -a ${ROIs_DIR}/${hemi}_Area_3a.nii.gz \
               -b ${ROIs_DIR}/${hemi}_Primary_Sensory_Cortex.nii.gz \
               -c ${ROIs_DIR}/${hemi}_Area_1.nii.gz \
               -d ${ROIs_DIR}/${hemi}_Area_2.nii.gz \
               -expr 'step(a+b+c+d)' \
               -prefix ${ROIs_DIR}/${hemi}_S1.nii.gz -overwrite
    done
fi

if [[ ${NEUROPYTHY} == "True" ]]; then
    echo "Separating ROIs from Neuropythy with separateROIs.py -benV option"
    cp ${OUTPUT_DIR}/benson14_varea.nii.gz  ${FS_DIR}/benson14_varea.nii.gz
    ${FLYWHEEL_BASE}/separateROIs.py -benV ${FS_DIR}/benson14_varea.nii.gz

    cp ${OUTPUT_DIR}/wang15_mplbl.nii.gz  ${FS_DIR}/wang15_mplbl.nii.gz
    ${FLYWHEEL_BASE}/separateROIs.py -benW ${FS_DIR}/wang15_mplbl.nii.gz
fi

if [[ ${APARC2009} == "True" ]]; then
    cp ${OUTPUT_DIR}/aparc.a2009s+aseg.nii.gz    ${FS_DIR}/aparc.a2009s+aseg.nii.gz    
    ${FLYWHEEL_BASE}/separateROIs.py -aparc2009 ${FS_DIR}/aparc.a2009s+aseg.nii.gz
    # split Brain Stem to Left and Right
    mri_convert -at ${MRI_DIR}/transforms/talairach.xfm -rt nearest \
                    ${ROIs_DIR}/Brain-Stem.nii.gz ${ROIs_DIR}/tmp.nii.gz
    3dcalc -a ${ROIs_DIR}/tmp.nii.gz -expr 'a*step(-2-x)' -prefix ${ROIs_DIR}/Right-tmp.nii.gz -overwrite
    3dcalc -a ${ROIs_DIR}/tmp.nii.gz -expr 'a*step(x-2)' -prefix ${ROIs_DIR}/Left-tmp.nii.gz -overwrite
    mri_convert -ait ${MRI_DIR}/transforms/talairach.xfm -rt nearest \
                    ${ROIs_DIR}/Right-tmp.nii.gz ${ROIs_DIR}/Right-Brain-Stem.nii.gz
    mri_convert -ait ${MRI_DIR}/transforms/talairach.xfm -rt nearest \
                    ${ROIs_DIR}/Left-tmp.nii.gz ${ROIs_DIR}/Left-Brain-Stem.nii.gz
    rm ${ROIs_DIR}/tmp.nii.gz ${ROIs_DIR}/Right-tmp.nii.gz ${ROIs_DIR}/Left-tmp.nii.gz
fi


# Brainstem
if [[ ${BRAINSTEM} == "True" ]]; then
    cp ${OUTPUT_DIR}/brainstemSsLabels.FSvoxelSpace.nii.gz ${FS_DIR}/brainstemSsLabels.FSvoxelSpace.nii.gz
    ${FLYWHEEL_BASE}/separateROIs.py -bs ${FS_DIR}/brainstemSsLabels.FSvoxelSpace.nii.gz
    
fi


# Hippocampus and Amygdala
if [[ ${HIPPOCAMPUS} == "True" ]]; then
    cp ${OUTPUT_DIR}/*h.hippoAmygLabels-T1.FSvoxelSpace.nii.gz ${FS_DIR}/
    ${FLYWHEEL_BASE}/separateROIs.py -hipp ${FS_DIR}/
    
fi


###############################################################################
# Write aseg stats to a table
if [[ $ASEG_CSV == "True" ]]; then
  echo -e "$CONTAINER  Exporting stats files csv..."
  asegstats2table -s "${SUBJECT_ID}" \
      --delimiter comma \
      --tablefile="${OUTPUT_DIR}/${SUBJECT_ID}_aseg_stats_vol_mm3.csv"

  # Parse the aparc files and write to table
  hemi="lh rh"
  parc="aparc.a2009s aparc"
  for h in $hemi; do
      for p in $parc; do
        aparcstats2table -s "${SUBJECT_ID}" \
          --hemi=$h \
          --delimiter=comma \
          --parc=$p \
          --tablefile="${OUTPUT_DIR}/${SUBJECT_ID}_${h}_${p}_stats_area_mm2.csv"
      done
    done

    if [[ ${THALAMUS} == "True" ]]; then
        for h in $hemi; do
            # Create a symbolic link to the development version of this output specified
            # by ${SUFFIX} in 
            # thalamic-nuclei.${h}.${SUFFIX}.T1.stats
            ln -sfn ${SUBJECTS_DIR}/${SUBJECT_ID}/stats/thalamic-nuclei.${h}.*.T1.stats ${SUBJECTS_DIR}/${SUBJECT_ID}/stats/thalamic-nuclei.${h}.T1.stats
            asegstats2table -s "${SUBJECT_ID}" \
              --delimiter=comma \
              --statsfile=thalamic-nuclei.${h}.T1.stats \
              --tablefile="${OUTPUT_DIR}/${SUBJECT_ID}_thalamic-nuclei.${h}.T1.csv"
        done
    fi
fi


###############################################################################
# Compress Recon-all output directory
echo -e "$CONTAINER  Compressing final outputs..."

# Set file permissions prior to compression
chmod -R 777 ${WORK_DIR}
cd ${OUTPUT_DIR}
zip -r /${OUTPUT_DIR}/${GEAR}_"${SUBJECT_ID}"`date +"_D%m-%d-%yT%H-%M"`.zip "${SUBJECT_ID}"
rm -rf $OUTPUT_DIR/$SUBJECT_ID

# Now compress the FS_DIR that will be input to the rtp_pipeline
zip -r fs.zip fs
rm -rf $OUTPUT_DIR/fs
rm -rf $OUTPUT_DIR/templates

# Delete the tmp MCR folder, it breaks FW and wastes space
rm -rf $OUTPUT_DIR/$MCR_CACHE_FOLDER_NAME


###############################################################################
# FINISH

# Get a list of the files in the output directory
outputs=$(find $OUTPUT_DIR/* -maxdepth 0 -type f -name "*.zip")

# If outputs exist, generate metadata, and exit
if [[ -z $outputs ]]; then
  echo "$CONTAINER  GEAR FAILED... Exiting(1)"
  exit 1
else
  # Set permissions for outputs (prevent root only r/w)
  chmod -R 777 $OUTPUT_DIR
  echo -e "$CONTAINER  Done!"
  exit 0
fi
